#!/bin/bash

# Generate all USAJobs reports

echo "ğŸ“Š USAJobs Report Generation"
echo "============================="

# Create reports directory if it doesn't exist
mkdir -p reports

# Check if data exists
if [ ! -f "data/usajobs.parquet" ]; then
    echo "âŒ Data file not found: data/usajobs.parquet"
    echo "   Run the pipeline first: python run_pipeline.py"
    exit 1
fi

echo "ğŸ“… Generating Job Explorer Dashboard..."
cd report_generation
./render_explorer.sh
cd ..

echo ""
echo "âœ… Reports Generated!"
echo "ğŸ“ View reports in: reports/"
echo ""
echo "Available Reports:"
echo "  ğŸ“Š Job Explorer: reports/job_explorer.html"
echo "  ğŸ“ˆ Analysis Report: reports/rationalization_analysis.html (generated by pipeline)"
echo "  ğŸ” Content Mismatches: reports/content_mismatch_analysis.html (generated by pipeline)"
echo "  ğŸ“‰ Scraping Effectiveness: reports/scraping_effectiveness_report.html (generated by pipeline)"
echo "  ğŸ”¬ Scraping vs API: reports/scraping_vs_api_comparison.html (generated by pipeline)"
echo ""
echo "ğŸ’¡ Tip: Run the full pipeline to generate all reports"