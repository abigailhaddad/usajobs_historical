---
title: "USAJobs Data Rationalization Analysis"
author: "Enhanced Pipeline Analysis"
subtitle: "Analysis of unified dataset combining historical and current USAJobs data"
format:
  html:
    toc: true
    toc-depth: 3
    code-fold: true
execute:
  echo: true
  warning: false
---

```{python}
import duckdb
import pandas as pd
import numpy as np
import json
from collections import Counter
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns

# Connect to the unified dataset
conn = duckdb.connect("data/unified_pipeline_20250613_042206.duckdb")
```

## Dataset Overview

```{python}
# Basic dataset statistics
total_records = conn.execute("SELECT COUNT(*) FROM unified_jobs").fetchone()[0]
date_range = conn.execute("SELECT MIN(open_date), MAX(open_date) FROM unified_jobs").fetchone()
data_sources = conn.execute("SELECT data_sources, COUNT(*) FROM unified_jobs GROUP BY data_sources").fetchall()

print(f"üìä Total Records: {total_records:,}")
print(f"üìÖ Date Range: {date_range[0]} to {date_range[1]}")
print("\nüîÑ Data Sources:")

# Count overlaps and unique sources
current_only = 0
historical_only = 0
overlap = 0

for sources_json, count in data_sources:
    if sources_json:
        sources_list = json.loads(sources_json)
        if 'current_api' in sources_list and any('historical' in s for s in sources_list):
            overlap += count
        elif 'current_api' in sources_list:
            current_only += count
        else:
            historical_only += count

print(f"   üìò Current API only: {current_only:,} jobs")
print(f"   üìó Historical API only: {historical_only:,} jobs") 
print(f"   üîÑ Overlap (in both): {overlap:,} jobs")
print(f"\n   ‚ö†Ô∏è Note: The {overlap:,} overlapping jobs appear in both current and historical data.")
print(f"   These are being kept with current API data taking priority.")
```

## Data Source Comparison

### Sample Overlapping Jobs

```{python}
# Check if overlap samples table exists and has data
try:
    overlap_samples = conn.execute("SELECT * FROM overlap_samples ORDER BY control_number, source_type").fetchall()
    
    if overlap_samples:
        # Get field names
        field_info = conn.execute("PRAGMA table_info(overlap_samples)").fetchall()
        field_names = [row[1] for row in field_info if row[1] not in ['control_number', 'source_type']]
        
        # Group by control number
        control_groups = {}
        for row in overlap_samples:
            control_num = row[0]
            source_type = row[1] 
            if control_num not in control_groups:
                control_groups[control_num] = {}
            control_groups[control_num][source_type] = row[2:]  # Skip control_number and source_type
        
        # Display comparisons
        for i, (control_num, sources) in enumerate(control_groups.items(), 1):
            if 'historical' in sources and 'current' in sources:
                print(f"EXAMPLE {i}: Job {control_num}")
                print("-" * 80)
                
                hist_data = sources['historical']
                curr_data = sources['current'] 
                
                print(f"{'Field':<20} {'Historical':<30} {'Current':<30}")
                print("-" * 80)
                
                # Compare all important fields
                key_fields = ['position_title', 'agency_name', 'department_name', 'sub_agency', 'job_series', 
                             'min_grade', 'max_grade', 'pay_scale', 'min_salary', 'max_salary', 'salary_text',
                             'open_date', 'close_date', 'locations', 'work_schedule',
                             'telework_eligible', 'security_clearance_required', 'hiring_path',
                             'qualification_summary', 'major_duties', 'requirements', 'how_to_apply',
                             'benefits', 'education', 'job_summary', 'total_openings', 'promotion_potential']
                
                for field_idx, field_name in enumerate(field_names):
                    if field_name in key_fields:
                        hist_val = hist_data[field_idx] if hist_data[field_idx] else "‚ùå"
                        curr_val = curr_data[field_idx] if curr_data[field_idx] else "‚ùå"
                        
                        # Format for display
                        if isinstance(hist_val, (int, float)) and 'salary' in field_name:
                            hist_val = f"${hist_val:,.0f}" if hist_val != "‚ùå" else "‚ùå"
                        elif hist_val != "‚ùå":
                            # Handle text fields differently - show more for important content fields
                            if field_name in ['qualification_summary', 'major_duties', 'requirements', 'job_summary']:
                                hist_val = (str(hist_val)[:50] + "...") if len(str(hist_val)) > 50 else str(hist_val)
                            elif len(str(hist_val)) > 27:
                                hist_val = str(hist_val)[:27] + "..."
                            else:
                                hist_val = str(hist_val)
                            
                        if isinstance(curr_val, (int, float)) and 'salary' in field_name:
                            curr_val = f"${curr_val:,.0f}" if curr_val != "‚ùå" else "‚ùå"
                        elif curr_val != "‚ùå":
                            # Handle text fields differently - show more for important content fields  
                            if field_name in ['qualification_summary', 'major_duties', 'requirements', 'job_summary']:
                                curr_val = (str(curr_val)[:50] + "...") if len(str(curr_val)) > 50 else str(curr_val)
                            elif len(str(curr_val)) > 27:
                                curr_val = str(curr_val)[:27] + "..."
                            else:
                                curr_val = str(curr_val)
                        
                        # Mark differences
                        match_indicator = "‚úÖ" if str(hist_val) == str(curr_val) else "‚ùì"
                        
                        print(f"{field_name:<20} {str(hist_val):<30} {str(curr_val):<30} {match_indicator}")
                print()
                
    else:
        print("No overlap samples found for comparison.")
        
except Exception as e:
    print(f"Overlap analysis not available: {e}")
```

## Field Coverage Analysis

```{python}
# Get all fields from the schema (excluding metadata and empty fields)
all_fields_raw = conn.execute("PRAGMA table_info(unified_jobs)").fetchall()
all_fields = [
    (row[1],) for row in all_fields_raw 
    if row[1] not in ('data_sources', 'rationalization_date', 'confidence_score', 
                      'extraction_metadata', 'scraped_sections', 'full_content',
                      'announcement_number', 'posted_date', 'primary_location')
]

# Build dynamic coverage query for all fields
field_coverage_data = []

# Historical data coverage
hist_total = conn.execute("SELECT COUNT(*) FROM unified_jobs WHERE data_sources LIKE '%historical%'").fetchone()[0]
if hist_total > 0:
    for (field_name,) in all_fields:
        # Special handling for different field types
        if field_name in ['min_salary', 'max_salary', 'total_openings']:
            # Numeric fields - just check NOT NULL
            count_query = f"COUNT(CASE WHEN {field_name} IS NOT NULL THEN 1 END)"
        elif field_name in ['open_date', 'close_date', 'posted_date', 'rationalization_date']:
            # Date fields - just check NOT NULL
            count_query = f"COUNT(CASE WHEN {field_name} IS NOT NULL THEN 1 END)"
        else:
            # String fields - check NOT NULL and not empty
            count_query = f"COUNT(CASE WHEN {field_name} IS NOT NULL AND {field_name} != '' THEN 1 END)"
        
        result = conn.execute(f"""
            SELECT 
                {count_query} as complete_count,
                ROUND({count_query} * 100.0 / COUNT(*), 1) as percentage
            FROM unified_jobs WHERE data_sources LIKE '%historical%'
        """).fetchone()
        
        field_coverage_data.append({
            'Source': 'Historical', 
            'Field': field_name, 
            'Complete': result[0], 
            'Total': hist_total, 
            'Percentage': result[1]
        })

# Current data coverage  
curr_total = conn.execute("SELECT COUNT(*) FROM unified_jobs WHERE data_sources LIKE '%current%'").fetchone()[0]
if curr_total > 0:
    for (field_name,) in all_fields:
        # Special handling for different field types
        if field_name in ['min_salary', 'max_salary', 'total_openings']:
            # Numeric fields - just check NOT NULL
            count_query = f"COUNT(CASE WHEN {field_name} IS NOT NULL THEN 1 END)"
        elif field_name in ['open_date', 'close_date', 'posted_date', 'rationalization_date']:
            # Date fields - just check NOT NULL
            count_query = f"COUNT(CASE WHEN {field_name} IS NOT NULL THEN 1 END)"
        else:
            # String fields - check NOT NULL and not empty
            count_query = f"COUNT(CASE WHEN {field_name} IS NOT NULL AND {field_name} != '' THEN 1 END)"
        
        result = conn.execute(f"""
            SELECT 
                {count_query} as complete_count,
                ROUND({count_query} * 100.0 / COUNT(*), 1) as percentage
            FROM unified_jobs WHERE data_sources LIKE '%current%'
        """).fetchone()
        
        field_coverage_data.append({
            'Source': 'Current', 
            'Field': field_name, 
            'Complete': result[0], 
            'Total': curr_total, 
            'Percentage': result[1]
        })

# Create DataFrame and pivot for better visualization
coverage_df = pd.DataFrame(field_coverage_data)
if not coverage_df.empty:
    # Create pivot table for side-by-side comparison
    pivot_df = coverage_df.pivot(index='Field', columns='Source', values='Percentage').fillna(0)
    pivot_df = pivot_df.round(1)
    
    # Sort by field importance
    field_order = ['control_number', 'position_title', 'agency_name', 'department_name', 
                   'min_salary', 'max_salary', 'job_series', 'locations', 'work_schedule',
                   'major_duties', 'qualification_summary', 'requirements', 'education',
                   'benefits', 'how_to_apply', 'hiring_path']
    
    # Reorder fields that exist
    existing_fields = [f for f in field_order if f in pivot_df.index]
    other_fields = sorted([f for f in pivot_df.index if f not in field_order])
    pivot_df = pivot_df.reindex(existing_fields + other_fields)
    
    print("üìä Field Coverage Comparison (% of records with data):")
    print(pivot_df.to_string())
    
    # Highlight fields with significant differences
    print("\nüîç Fields with Major Coverage Differences:")
    for field in pivot_df.index:
        if 'Historical' in pivot_df.columns and 'Current' in pivot_df.columns:
            diff = abs(pivot_df.loc[field, 'Historical'] - pivot_df.loc[field, 'Current'])
            if diff > 20:
                hist_val = pivot_df.loc[field, 'Historical']
                curr_val = pivot_df.loc[field, 'Current']
                print(f"   {field}: Historical={hist_val}%, Current={curr_val}% (diff={diff:.1f}%)")
```

## Missing Duties and Qualifications Analysis

```{python}
# Find jobs missing major_duties
missing_duties = conn.execute("""
    SELECT 
        control_number,
        position_title,
        agency_name,
        data_sources,
        CASE WHEN major_duties IS NULL THEN 'NULL' 
             WHEN major_duties = '' THEN 'EMPTY' 
             ELSE 'PRESENT' END as duties_status
    FROM unified_jobs 
    WHERE major_duties IS NULL OR major_duties = ''
    ORDER BY control_number
    LIMIT 20
""").fetchall()

print("‚ùå Jobs Missing Major Duties (first 20):")
print("Control Number | Position Title | Agency | Source | Status")
print("-" * 80)
for control, title, agency, sources, status in missing_duties:
    title_short = (title[:30] + "...") if title and len(title) > 30 else (title or "N/A")
    agency_short = (agency[:20] + "...") if agency and len(agency) > 20 else (agency or "N/A")
    source_list = json.loads(sources) if sources else ['Unknown']
    source_short = source_list[0] if source_list else 'Unknown'
    print(f"{control} | {title_short:<30} | {agency_short:<20} | {source_short:<10} | {status}")

# Count by source
duties_by_source = conn.execute("""
    SELECT 
        CASE WHEN data_sources LIKE '%historical%' AND data_sources LIKE '%current%' THEN 'Both'
             WHEN data_sources LIKE '%historical%' THEN 'Historical Only'
             WHEN data_sources LIKE '%current%' THEN 'Current Only'
             ELSE 'Other' END as source_type,
        COUNT(CASE WHEN major_duties IS NULL OR major_duties = '' THEN 1 END) as missing_duties,
        COUNT(*) as total,
        ROUND(COUNT(CASE WHEN major_duties IS NULL OR major_duties = '' THEN 1 END) * 100.0 / COUNT(*), 1) as missing_pct
    FROM unified_jobs
    GROUP BY source_type
""").fetchall()

print(f"\nüìà Missing Duties by Source:")
for source, missing, total, pct in duties_by_source:
    print(f"   {source}: {missing}/{total} ({pct}%)")

print("\n" + "="*50)

# Find jobs missing qualification_summary
missing_quals = conn.execute("""
    SELECT 
        control_number,
        position_title,
        agency_name,
        data_sources,
        CASE WHEN qualification_summary IS NULL THEN 'NULL' 
             WHEN qualification_summary = '' THEN 'EMPTY' 
             ELSE 'PRESENT' END as quals_status
    FROM unified_jobs 
    WHERE qualification_summary IS NULL OR qualification_summary = ''
    ORDER BY control_number
    LIMIT 20
""").fetchall()

print("‚ùå Jobs Missing Qualification Summary (first 20):")
print("Control Number | Position Title | Agency | Source | Status")
print("-" * 80)
for control, title, agency, sources, status in missing_quals:
    title_short = (title[:30] + "...") if title and len(title) > 30 else (title or "N/A")
    agency_short = (agency[:20] + "...") if agency and len(agency) > 20 else (agency or "N/A")
    source_list = json.loads(sources) if sources else ['Unknown']
    source_short = source_list[0] if source_list else 'Unknown'
    print(f"{control} | {title_short:<30} | {agency_short:<20} | {source_short:<10} | {status}")

# Count by source
quals_by_source = conn.execute("""
    SELECT 
        CASE WHEN data_sources LIKE '%historical%' AND data_sources LIKE '%current%' THEN 'Both'
             WHEN data_sources LIKE '%historical%' THEN 'Historical Only'
             WHEN data_sources LIKE '%current%' THEN 'Current Only'
             ELSE 'Other' END as source_type,
        COUNT(CASE WHEN qualification_summary IS NULL OR qualification_summary = '' THEN 1 END) as missing_quals,
        COUNT(*) as total,
        ROUND(COUNT(CASE WHEN qualification_summary IS NULL OR qualification_summary = '' THEN 1 END) * 100.0 / COUNT(*), 1) as missing_pct
    FROM unified_jobs
    GROUP BY source_type
""").fetchall()

print(f"\nüìà Missing Qualifications by Source:")
for source, missing, total, pct in quals_by_source:
    print(f"   {source}: {missing}/{total} ({pct}%)")
```