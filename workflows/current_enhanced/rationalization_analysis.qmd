---
title: "USAJobs Data Rationalization Analysis"
author: "Enhanced Pipeline Analysis"
subtitle: "Analysis of unified dataset combining historical and current USAJobs data"
format:
  html:
    toc: true
    toc-depth: 3
    code-fold: true
execute:
  echo: true
  warning: false
---

```{python}
import duckdb
import pandas as pd
import numpy as np
import json
from collections import Counter
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns

# Connect to the unified dataset
conn = duckdb.connect("data/unified_test_with_scraping.duckdb")
```

## Dataset Overview

```{python}
# Basic dataset statistics
total_records = conn.execute("SELECT COUNT(*) FROM unified_jobs").fetchone()[0]
date_range = conn.execute("SELECT MIN(open_date), MAX(open_date) FROM unified_jobs").fetchone()
data_sources = conn.execute("SELECT data_sources, COUNT(*) FROM unified_jobs GROUP BY data_sources").fetchall()

print(f"ðŸ“Š Total Records: {total_records:,}")
print(f"ðŸ“… Date Range: {date_range[0]} to {date_range[1]}")
print(f"ðŸ“ˆ Average Confidence: {conn.execute('SELECT AVG(confidence_score) FROM unified_jobs').fetchone()[0]:.3f}")
print("\nðŸ”„ Data Sources:")
for source, count in data_sources:
    print(f"   {json.loads(source)[0] if source else 'Unknown'}: {count:,} records")
```

## Data Source Comparison

### Sample Overlapping Jobs

```{python}
# Find a couple overlapping jobs for side-by-side comparison
overlap_jobs = conn.execute("""
    WITH historical_controls AS (
        SELECT DISTINCT control_number FROM unified_jobs WHERE data_sources LIKE '%historical%'
    ),
    current_controls AS (
        SELECT DISTINCT control_number FROM unified_jobs WHERE data_sources LIKE '%current%'
    )
    SELECT h.control_number
    FROM historical_controls h
    INNER JOIN current_controls c ON h.control_number = c.control_number
    ORDER BY RANDOM()
    LIMIT 2
""").fetchall()

if overlap_jobs:
    for i, (control_num,) in enumerate(overlap_jobs, 1):
        print(f"EXAMPLE {i}: Job {control_num}")
        print("-" * 50)
        
        # Get key fields from both sources
        hist_job = conn.execute("""
            SELECT position_title, agency_name, job_series, min_salary, max_salary, 
                   work_schedule, major_duties, qualification_summary
            FROM unified_jobs 
            WHERE control_number = ? AND data_sources LIKE '%historical%'
        """, [control_num]).fetchone()
        
        curr_job = conn.execute("""
            SELECT position_title, agency_name, job_series, min_salary, max_salary,
                   work_schedule, major_duties, qualification_summary
            FROM unified_jobs
            WHERE control_number = ? AND data_sources LIKE '%current%'
        """, [control_num]).fetchone()
        
        fields = ['Position Title', 'Agency', 'Job Series', 'Min Salary', 'Max Salary', 
                 'Work Schedule', 'Major Duties', 'Qualifications']
        
        print(f"{'Field':<15} {'Historical':<30} {'Current':<30}")
        print("-" * 75)
        
        for j, field in enumerate(fields):
            hist_val = hist_job[j] if hist_job and hist_job[j] else "âŒ"
            curr_val = curr_job[j] if curr_job and curr_job[j] else "âŒ"
            
            # Format for display
            if isinstance(hist_val, (int, float)) and 'Salary' in field:
                hist_val = f"${hist_val:,.0f}" if hist_val != "âŒ" else "âŒ"
            elif hist_val != "âŒ" and len(str(hist_val)) > 27:
                hist_val = str(hist_val)[:27] + "..."
                
            if isinstance(curr_val, (int, float)) and 'Salary' in field:
                curr_val = f"${curr_val:,.0f}" if curr_val != "âŒ" else "âŒ"
            elif curr_val != "âŒ" and len(str(curr_val)) > 27:
                curr_val = str(curr_val)[:27] + "..."
            
            print(f"{field:<15} {str(hist_val):<30} {str(curr_val):<30}")
        print()
```

## Field Coverage Analysis

```{python}
# Field coverage analysis - long format instead of wide
field_coverage_data = []

# Historical data coverage
hist_total = conn.execute("SELECT COUNT(*) FROM unified_jobs WHERE data_sources LIKE '%historical%'").fetchone()[0]
if hist_total > 0:
    hist_fields = conn.execute("""
        SELECT 
            'position_title' as field_name,
            COUNT(CASE WHEN position_title IS NOT NULL AND position_title != '' THEN 1 END) as complete_count,
            ROUND(COUNT(CASE WHEN position_title IS NOT NULL AND position_title != '' THEN 1 END) * 100.0 / COUNT(*), 1) as percentage
        FROM unified_jobs WHERE data_sources LIKE '%historical%'
        
        UNION ALL SELECT 'agency_name', COUNT(CASE WHEN agency_name IS NOT NULL AND agency_name != '' THEN 1 END), 
                  ROUND(COUNT(CASE WHEN agency_name IS NOT NULL AND agency_name != '' THEN 1 END) * 100.0 / COUNT(*), 1)
        FROM unified_jobs WHERE data_sources LIKE '%historical%'
        
        UNION ALL SELECT 'job_series', COUNT(CASE WHEN job_series IS NOT NULL AND job_series != '' AND job_series != '0000' THEN 1 END),
                  ROUND(COUNT(CASE WHEN job_series IS NOT NULL AND job_series != '' AND job_series != '0000' THEN 1 END) * 100.0 / COUNT(*), 1)
        FROM unified_jobs WHERE data_sources LIKE '%historical%'
        
        UNION ALL SELECT 'salary_range', COUNT(CASE WHEN min_salary IS NOT NULL AND max_salary IS NOT NULL THEN 1 END),
                  ROUND(COUNT(CASE WHEN min_salary IS NOT NULL AND max_salary IS NOT NULL THEN 1 END) * 100.0 / COUNT(*), 1)
        FROM unified_jobs WHERE data_sources LIKE '%historical%'
        
        UNION ALL SELECT 'locations', COUNT(CASE WHEN locations IS NOT NULL AND locations != '' THEN 1 END),
                  ROUND(COUNT(CASE WHEN locations IS NOT NULL AND locations != '' THEN 1 END) * 100.0 / COUNT(*), 1)
        FROM unified_jobs WHERE data_sources LIKE '%historical%'
        
        UNION ALL SELECT 'major_duties', COUNT(CASE WHEN major_duties IS NOT NULL AND major_duties != '' THEN 1 END),
                  ROUND(COUNT(CASE WHEN major_duties IS NOT NULL AND major_duties != '' THEN 1 END) * 100.0 / COUNT(*), 1)
        FROM unified_jobs WHERE data_sources LIKE '%historical%'
        
        UNION ALL SELECT 'qualification_summary', COUNT(CASE WHEN qualification_summary IS NOT NULL AND qualification_summary != '' THEN 1 END),
                  ROUND(COUNT(CASE WHEN qualification_summary IS NOT NULL AND qualification_summary != '' THEN 1 END) * 100.0 / COUNT(*), 1)
        FROM unified_jobs WHERE data_sources LIKE '%historical%'
        
        UNION ALL SELECT 'work_schedule', COUNT(CASE WHEN work_schedule IS NOT NULL AND work_schedule != '' THEN 1 END),
                  ROUND(COUNT(CASE WHEN work_schedule IS NOT NULL AND work_schedule != '' THEN 1 END) * 100.0 / COUNT(*), 1)
        FROM unified_jobs WHERE data_sources LIKE '%historical%'
    """).fetchall()
    
    for field, count, pct in hist_fields:
        field_coverage_data.append({'Source': 'Historical', 'Field': field, 'Complete': count, 'Total': hist_total, 'Percentage': pct})

# Current data coverage
curr_total = conn.execute("SELECT COUNT(*) FROM unified_jobs WHERE data_sources LIKE '%current%'").fetchone()[0]
if curr_total > 0:
    curr_fields = conn.execute("""
        SELECT 
            'position_title' as field_name,
            COUNT(CASE WHEN position_title IS NOT NULL AND position_title != '' THEN 1 END) as complete_count,
            ROUND(COUNT(CASE WHEN position_title IS NOT NULL AND position_title != '' THEN 1 END) * 100.0 / COUNT(*), 1) as percentage
        FROM unified_jobs WHERE data_sources LIKE '%current%'
        
        UNION ALL SELECT 'agency_name', COUNT(CASE WHEN agency_name IS NOT NULL AND agency_name != '' THEN 1 END), 
                  ROUND(COUNT(CASE WHEN agency_name IS NOT NULL AND agency_name != '' THEN 1 END) * 100.0 / COUNT(*), 1)
        FROM unified_jobs WHERE data_sources LIKE '%current%'
        
        UNION ALL SELECT 'job_series', COUNT(CASE WHEN job_series IS NOT NULL AND job_series != '' AND job_series != '0000' THEN 1 END),
                  ROUND(COUNT(CASE WHEN job_series IS NOT NULL AND job_series != '' AND job_series != '0000' THEN 1 END) * 100.0 / COUNT(*), 1)
        FROM unified_jobs WHERE data_sources LIKE '%current%'
        
        UNION ALL SELECT 'salary_range', COUNT(CASE WHEN min_salary IS NOT NULL AND max_salary IS NOT NULL THEN 1 END),
                  ROUND(COUNT(CASE WHEN min_salary IS NOT NULL AND max_salary IS NOT NULL THEN 1 END) * 100.0 / COUNT(*), 1)
        FROM unified_jobs WHERE data_sources LIKE '%current%'
        
        UNION ALL SELECT 'locations', COUNT(CASE WHEN locations IS NOT NULL AND locations != '' THEN 1 END),
                  ROUND(COUNT(CASE WHEN locations IS NOT NULL AND locations != '' THEN 1 END) * 100.0 / COUNT(*), 1)
        FROM unified_jobs WHERE data_sources LIKE '%current%'
        
        UNION ALL SELECT 'major_duties', COUNT(CASE WHEN major_duties IS NOT NULL AND major_duties != '' THEN 1 END),
                  ROUND(COUNT(CASE WHEN major_duties IS NOT NULL AND major_duties != '' THEN 1 END) * 100.0 / COUNT(*), 1)
        FROM unified_jobs WHERE data_sources LIKE '%current%'
        
        UNION ALL SELECT 'qualification_summary', COUNT(CASE WHEN qualification_summary IS NOT NULL AND qualification_summary != '' THEN 1 END),
                  ROUND(COUNT(CASE WHEN qualification_summary IS NOT NULL AND qualification_summary != '' THEN 1 END) * 100.0 / COUNT(*), 1)
        FROM unified_jobs WHERE data_sources LIKE '%current%'
        
        UNION ALL SELECT 'work_schedule', COUNT(CASE WHEN work_schedule IS NOT NULL AND work_schedule != '' THEN 1 END),
                  ROUND(COUNT(CASE WHEN work_schedule IS NOT NULL AND work_schedule != '' THEN 1 END) * 100.0 / COUNT(*), 1)
        FROM unified_jobs WHERE data_sources LIKE '%current%'
    """).fetchall()
    
    for field, count, pct in curr_fields:
        field_coverage_data.append({'Source': 'Current', 'Field': field, 'Complete': count, 'Total': curr_total, 'Percentage': pct})

# Display the long format table
coverage_df = pd.DataFrame(field_coverage_data)
if not coverage_df.empty:
    print("ðŸ“Š Field Coverage by Source (Long Format):")
    print(coverage_df.to_string(index=False))
```

## Missing Duties and Qualifications Analysis

```{python}
# Find jobs missing major_duties
missing_duties = conn.execute("""
    SELECT 
        control_number,
        position_title,
        agency_name,
        data_sources,
        CASE WHEN major_duties IS NULL THEN 'NULL' 
             WHEN major_duties = '' THEN 'EMPTY' 
             ELSE 'PRESENT' END as duties_status
    FROM unified_jobs 
    WHERE major_duties IS NULL OR major_duties = ''
    ORDER BY control_number
    LIMIT 20
""").fetchall()

print("âŒ Jobs Missing Major Duties (first 20):")
print("Control Number | Position Title | Agency | Source | Status")
print("-" * 80)
for control, title, agency, sources, status in missing_duties:
    title_short = (title[:30] + "...") if title and len(title) > 30 else (title or "N/A")
    agency_short = (agency[:20] + "...") if agency and len(agency) > 20 else (agency or "N/A")
    source_list = json.loads(sources) if sources else ['Unknown']
    source_short = source_list[0] if source_list else 'Unknown'
    print(f"{control} | {title_short:<30} | {agency_short:<20} | {source_short:<10} | {status}")

# Count by source
duties_by_source = conn.execute("""
    SELECT 
        CASE WHEN data_sources LIKE '%historical%' AND data_sources LIKE '%current%' THEN 'Both'
             WHEN data_sources LIKE '%historical%' THEN 'Historical Only'
             WHEN data_sources LIKE '%current%' THEN 'Current Only'
             ELSE 'Other' END as source_type,
        COUNT(CASE WHEN major_duties IS NULL OR major_duties = '' THEN 1 END) as missing_duties,
        COUNT(*) as total,
        ROUND(COUNT(CASE WHEN major_duties IS NULL OR major_duties = '' THEN 1 END) * 100.0 / COUNT(*), 1) as missing_pct
    FROM unified_jobs
    GROUP BY source_type
""").fetchall()

print(f"\nðŸ“ˆ Missing Duties by Source:")
for source, missing, total, pct in duties_by_source:
    print(f"   {source}: {missing}/{total} ({pct}%)")

print("\n" + "="*50)

# Find jobs missing qualification_summary
missing_quals = conn.execute("""
    SELECT 
        control_number,
        position_title,
        agency_name,
        data_sources,
        CASE WHEN qualification_summary IS NULL THEN 'NULL' 
             WHEN qualification_summary = '' THEN 'EMPTY' 
             ELSE 'PRESENT' END as quals_status
    FROM unified_jobs 
    WHERE qualification_summary IS NULL OR qualification_summary = ''
    ORDER BY control_number
    LIMIT 20
""").fetchall()

print("âŒ Jobs Missing Qualification Summary (first 20):")
print("Control Number | Position Title | Agency | Source | Status")
print("-" * 80)
for control, title, agency, sources, status in missing_quals:
    title_short = (title[:30] + "...") if title and len(title) > 30 else (title or "N/A")
    agency_short = (agency[:20] + "...") if agency and len(agency) > 20 else (agency or "N/A")
    source_list = json.loads(sources) if sources else ['Unknown']
    source_short = source_list[0] if source_list else 'Unknown'
    print(f"{control} | {title_short:<30} | {agency_short:<20} | {source_short:<10} | {status}")

# Count by source
quals_by_source = conn.execute("""
    SELECT 
        CASE WHEN data_sources LIKE '%historical%' AND data_sources LIKE '%current%' THEN 'Both'
             WHEN data_sources LIKE '%historical%' THEN 'Historical Only'
             WHEN data_sources LIKE '%current%' THEN 'Current Only'
             ELSE 'Other' END as source_type,
        COUNT(CASE WHEN qualification_summary IS NULL OR qualification_summary = '' THEN 1 END) as missing_quals,
        COUNT(*) as total,
        ROUND(COUNT(CASE WHEN qualification_summary IS NULL OR qualification_summary = '' THEN 1 END) * 100.0 / COUNT(*), 1) as missing_pct
    FROM unified_jobs
    GROUP BY source_type
""").fetchall()

print(f"\nðŸ“ˆ Missing Qualifications by Source:")
for source, missing, total, pct in quals_by_source:
    print(f"   {source}: {missing}/{total} ({pct}%)")
```