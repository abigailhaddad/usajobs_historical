---
title: "Federal Job Postings Analysis: Recent Government Hiring Activity"
author: "Data Analysis"
date: today
format:
  html:
    theme: cosmo
    toc: true
    code-fold: show
    fig-width: 10
    fig-height: 6
jupyter: python3
---

# Federal Job Postings Analysis: Recent Government Hiring Activity

This analysis examines federal hiring patterns using both **historical job postings** (all jobs that opened in 2024-2025) and **current job openings** (jobs still accepting applications as of July 2025). All jobs are grouped by their **position open date** (when the job was first posted).

## Data Loading and Preparation

```{python}
import pandas as pd
from great_tables import GT

print("ðŸ“Š Loading USAJobs data...")

# Load current jobs (both 2024 and 2025)
current_2024 = pd.read_parquet('data/current_jobs_2024.parquet')
current_2025 = pd.read_parquet('data/current_jobs_2025.parquet')
current_df = pd.concat([current_2024, current_2025], ignore_index=True)

# Load historical data (2024 and 2025)
historical_2024 = pd.read_parquet('data/historical_jobs_2024.parquet')
historical_2025 = pd.read_parquet('data/historical_jobs_2025.parquet')
historical_df = pd.concat([historical_2024, historical_2025], ignore_index=True)

print(f"Current jobs (2024 + 2025): {len(current_df):,}")
print(f"  - 2024 current jobs: {len(current_2024):,}")
print(f"  - 2025 current jobs: {len(current_2025):,}")
print(f"Historical jobs (2024 + 2025): {len(historical_df):,}")
print(f"  - 2024 historical jobs: {len(historical_2024):,}")
print(f"  - 2025 historical jobs: {len(historical_2025):,}")
```

```{python}
# Combine and deduplicate the datasets
print("\nðŸ”„ Combining and deduplicating datasets...")

# Add source column to track where each job came from
current_df['data_source'] = 'current'
historical_df['data_source'] = 'historical'

# Combine datasets
combined_df = pd.concat([current_df, historical_df], ignore_index=True)

print(f"Combined total: {len(combined_df):,}")

# Deduplicate based on usajobsControlNumber (keep the most recent)
initial_count = len(combined_df)
combined_df = combined_df.drop_duplicates(subset=['usajobsControlNumber'], keep='last')
final_count = len(combined_df)

print(f"After deduplication: {final_count:,}")
print(f"Duplicates removed: {initial_count - final_count:,}")
```

```{python}
# Basic data quality check
print("\nâœ… Data Quality Check:")
print(f"Total unique jobs: {final_count:,}")
print(f"Unique hiring agencies: {combined_df['hiringAgencyName'].nunique():,}")
print(f"Date range: {combined_df['positionOpenDate'].min()} to {combined_df['positionOpenDate'].max()}")
print(f"Jobs with null control numbers: {combined_df['usajobsControlNumber'].isna().sum():,}")

# Data source breakdown
print("\nðŸ“Š Data Source Breakdown:")
source_counts = combined_df['data_source'].value_counts()
for source, count in source_counts.items():
    print(f"  {source}: {count:,} jobs")
```

## Who's Hiring? Top Federal Agencies

```{python}
# Create hiring analysis table
from great_tables import GT

hiring_analysis = (combined_df
    .groupby('hiringAgencyName')
    .agg({
        'usajobsControlNumber': 'count',
        'minimumSalary': 'median',
        'maximumSalary': 'median'
    })
    .rename(columns={
        'usajobsControlNumber': 'job_postings',
        'minimumSalary': 'median_min_salary',
        'maximumSalary': 'median_max_salary'
    })
    .sort_values('job_postings', ascending=False)
    .reset_index()
)

# Format salary columns
hiring_analysis['median_min_salary'] = hiring_analysis['median_min_salary'].fillna(0).astype(int)
hiring_analysis['median_max_salary'] = hiring_analysis['median_max_salary'].fillna(0).astype(int)

# Display top 20 hiring agencies as a nice table
top_20_agencies = hiring_analysis.head(20).copy()

# Create the Great Table
(
    GT(top_20_agencies)
    .tab_header(
        title="Top 20 Federal Agencies by Job Postings (2024-2025)",
        subtitle="Ranked by total number of job postings by position open date"
    )
    .cols_label(
        hiringAgencyName="Agency",
        job_postings="Job Postings",
        median_min_salary="Median Min Salary",
        median_max_salary="Median Max Salary"
    )
    .fmt_number(
        columns=["job_postings"],
        use_seps=True
    )
    .fmt_currency(
        columns=["median_min_salary", "median_max_salary"],
        currency="USD",
        use_seps=True
    )
)
```

## Year-to-Year Comparison: January-June

```{python}
# Create year-to-year comparison for Jan-June
comparison_data = combined_df.copy()
# Ensure positionOpenDate is datetime
comparison_data['positionOpenDate'] = pd.to_datetime(comparison_data['positionOpenDate'], format='mixed')
comparison_data['year'] = comparison_data['positionOpenDate'].dt.year
comparison_data['month'] = comparison_data['positionOpenDate'].dt.month
comparison_data['month_name'] = comparison_data['positionOpenDate'].dt.strftime('%B')

# Filter for January-June only
jan_june_data = comparison_data[comparison_data['month'] <= 6]

# Create comparison table
year_comparison = (jan_june_data
    .groupby(['year', 'month_name', 'month'])
    .size()
    .reset_index(name='job_count')
    .pivot(index=['month', 'month_name'], columns='year', values='job_count')
    .fillna(0)
    .astype(int)
    .reset_index()
)

# Calculate change if both years present
if 2024 in year_comparison.columns and 2025 in year_comparison.columns:
    year_comparison['change'] = year_comparison[2025] - year_comparison[2024]
    year_comparison['pct_change'] = ((year_comparison[2025] - year_comparison[2024]) / year_comparison[2024] * 100).round(1)
    year_comparison['pct_change'] = year_comparison['pct_change'].replace([float('inf'), -float('inf')], 0)

# Format for display
year_comparison_display = year_comparison.copy()
for col in [2024, 2025]:
    if col in year_comparison_display.columns:
        year_comparison_display[col] = year_comparison_display[col].apply(lambda x: f"{x:,}")

if 'change' in year_comparison_display.columns:
    year_comparison_display['change'] = year_comparison_display['change'].apply(lambda x: f"{x:+,}" if x != 0 else "0")
    year_comparison_display['pct_change'] = year_comparison_display['pct_change'].apply(lambda x: f"{x:+.1f}%" if x != 0 else "0.0%")

# Rename columns for display
column_renames = {
    'month_name': 'Month',
    2024: '2024 Jobs',
    2025: '2025 Jobs',
    'change': 'Change',
    'pct_change': '% Change'
}
year_comparison_display = year_comparison_display.rename(columns=column_renames)
year_comparison_display = year_comparison_display.drop('month', axis=1)

# Display the table
print("ðŸ“Š Year-to-Year Comparison: Job Postings by Month (Jan-June)")
print("   Jobs grouped by position open date")
print()

from IPython.display import display
display(year_comparison_display)

print()
print("Note: This shows jobs that opened in each month, regardless of current status.")
```

## Monthly Breakdown by Position Open Date

```{python}
# Create monthly breakdown
import datetime
from great_tables import GT

# Convert positionOpenDate to datetime and extract year-month
combined_df['positionOpenDate'] = pd.to_datetime(combined_df['positionOpenDate'], format='mixed')
combined_df['year_month'] = combined_df['positionOpenDate'].dt.to_period('M')

# Create monthly counts by data source (before deduplication)
monthly_raw_counts = (pd.concat([current_df, historical_df], ignore_index=True)
    .assign(year_month=lambda x: pd.to_datetime(x['positionOpenDate'], format='mixed').dt.to_period('M'))
    .groupby(['year_month', 'data_source'])
    .size()
    .reset_index(name='job_count')
    .pivot(index='year_month', columns='data_source', values='job_count')
    .fillna(0)
    .astype(int)
    .reset_index()
)

# Create monthly counts after deduplication (for total column)
monthly_deduped_counts = (combined_df
    .groupby('year_month')
    .size()
    .reset_index(name='total_deduped')
)

# Merge the data
monthly_breakdown = monthly_raw_counts.merge(monthly_deduped_counts, on='year_month', how='left')
monthly_breakdown['total'] = monthly_breakdown['total_deduped']

# Sort by year_month
monthly_breakdown = monthly_breakdown.sort_values('year_month')

# Format the period for display
monthly_breakdown['month'] = monthly_breakdown['year_month'].astype(str)

# Select and reorder columns
columns_to_show = ['month', 'total']
if 'current' in monthly_breakdown.columns:
    columns_to_show.append('current')
if 'historical' in monthly_breakdown.columns:
    columns_to_show.append('historical')

monthly_display = monthly_breakdown[columns_to_show]

# Format the data for display
monthly_display_formatted = monthly_display.copy()
monthly_display_formatted['total'] = monthly_display_formatted['total'].apply(lambda x: f"{x:,}")
monthly_display_formatted['current'] = monthly_display_formatted['current'].apply(lambda x: f"{x:,}")
monthly_display_formatted['historical'] = monthly_display_formatted['historical'].apply(lambda x: f"{x:,}")

# Rename columns for display
monthly_display_formatted = monthly_display_formatted.rename(columns={
    'month': 'Month',
    'total': 'Total Jobs (Deduped)',
    'current': 'Current Jobs*',
    'historical': 'Historical Jobs'
})

# Create and display the table
print("ðŸ“… Monthly Job Postings by Position Open Date")
print("   Jobs grouped by when they were first posted")
print()

from IPython.display import display
display(monthly_display_formatted)

print()

# Add explanation for current jobs
if 'current' in monthly_display.columns:
    print("*Current jobs = jobs still accepting applications as of July 2025.")
    print("For 2024 dates, these represent jobs that opened in 2024 and remained open through July 2025.")
    print()
    print("Note: Current and Historical columns show raw counts (may include duplicates).")
    print("Total Jobs (Deduped) shows unique jobs after removing duplicates between datasets.")
```

## Summary Statistics

```{python}
# Overall summary
print("ðŸ“ˆ Federal Job Postings Summary (2024-2025):")
print(f"  â€¢ Total job postings: {final_count:,}")
print(f"  â€¢ Hiring agencies: {combined_df['hiringAgencyName'].nunique():,}")
print(f"  â€¢ Unique position titles: {combined_df['positionTitle'].nunique():,}")
print(f"  â€¢ Date range: {combined_df['positionOpenDate'].min().strftime('%Y-%m-%d')} to {combined_df['positionOpenDate'].max().strftime('%Y-%m-%d')}")

# Data source breakdown (raw counts before deduplication)
print(f"\nðŸ“Š Data Sources (Raw Counts):")
current_raw_count = len(current_df)
historical_raw_count = len(historical_df)
print(f"  â€¢ Current jobs (still open): {current_raw_count:,}")
print(f"  â€¢ Historical jobs (all 2025): {historical_raw_count:,}")
print(f"  â€¢ Total after deduplication: {final_count:,}")
print(f"  â€¢ Duplicates removed: {(current_raw_count + historical_raw_count) - final_count:,}")

# Salary statistics for jobs with salary data
salary_data = combined_df[(combined_df['minimumSalary'].notna()) & (combined_df['maximumSalary'].notna())]
if len(salary_data) > 0:
    print(f"\nðŸ’° Salary Statistics ({len(salary_data):,} jobs with salary data):")
    print(f"  â€¢ Median minimum salary: ${salary_data['minimumSalary'].median():,.0f}")
    print(f"  â€¢ Median maximum salary: ${salary_data['maximumSalary'].median():,.0f}")
    print(f"  â€¢ Highest max salary: ${salary_data['maximumSalary'].max():,.0f}")
```

## Data Notes

**Data Sources:**
- **Current Jobs API**: Real-time job postings currently open for applications as of July 2025
- **Historical Jobs API**: All job postings that opened in 2025 (including closed ones)

**Important Notes:**
- All jobs are grouped by their **position open date** (when the job was first posted)
- For 2024 jobs in the "Current" category: these are jobs that opened in 2024 but remained open through July 2025
- **Deduplication:** Jobs appearing in both datasets are deduplicated using the `usajobsControlNumber` field, keeping the most recent version
- **Coverage:** This analysis includes federal job postings with position open dates in 2024-2025, providing a comprehensive view of recent federal hiring activity

---
*Analysis generated on {python} datetime.now().strftime("%Y-%m-%d %H:%M:%S")*